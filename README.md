# Bias Amplification

This repository provides the code and experiments for â€œWhen Majority Rules, Minority Loses: Bias Amplification of Gradient Descentâ€,
by FranÃ§ois Bachoc, JÃ©rÃ´me Bolte, Ryan Boustany, and Jean-Michel Loubes.

Published at **NeurIPS 2025**.  
ğŸ“„ [Paper](https://arxiv.org/pdf/2505.13122)

## Overview

This work provides a theoretical and empirical analysis of **bias amplification** during gradient-based training.  
We show that standard optimization dynamics tend to reinforce pre-existing population imbalances,  
creating a *stereotypical gap* between majority and minority subgroups.

## Repository Structure

```text
bias_amplification/
â”œâ”€â”€ models_scratch/   # core models
â”œâ”€â”€ src/              # core training, and evaluation code
â”œâ”€â”€ notebooks/        # analysis and visualization notebooks
â”œâ”€â”€ results/         
â””â”€â”€ README.md
```

## Reproducibility

1. Install dependencies (Python â‰¥ 3.8, PyTorch â‰¥ 2.0)  
2. Prepare datasets (e.g., CIFAR-10, EuroSAT)  
3. Run experiments:

```
python src/CIFAR2.py \
  --num_runs 10 \
  --lr 8e-3 \
  --network resnet18 \
  --epochs_list 5000 \
  --kappa 90.0 \
  --tau 90.0
```

4. Visualize results with Jupyter notebooks in notebooks.

---

## Reference

```
@inproceedings{bachoc2025bias,
  title     = {When Majority Rules, Minority Loses: Bias Amplification of Gradient Descent},
  author    = {Bachoc, FranÃ§ois and Bolte, JÃ©rÃ´me and Boustany, Ryan and Loubes, Jean-Michel},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2025}
}
```
